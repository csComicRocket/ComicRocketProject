# Lucas Berge 2013

import LunarModule.pageTree
#import errorNotification
#import urllib.request
#import urllib.error
import urllib2
from bs4 import BeautifulSoup

(_CACHE, _WEB) = range(2)
    
    
""" fillNode(response:urllib.response, comicNum:int, nodeNum:int, parentNum:int)
    Takes a non-error response, parses the content and puts it into and adds a node
    to the pageTree object """
def fillNode(tree, pageStr, headerDict, url, comicNum, nodeNum=None, parentNum=None):        #comicID argument

    contentType = headerDict["Content-Type"]
    rspDate     = headerDict["Date"]
    #mimeType    = headerDict["MIME-Version"]    #MIME and contentType appear to be the same thing
    
    tree.createPageNode(url, nodeNum, parentNum, _WEB, pageStr, contentType, rspDate)
    tree.setComicId(nodeNum, comicNum)
    
    #if mimeType is None:                            #MIME and ContentType are interchangeable
    #    tree.setMimeType(0, contentType)
    #else:
    #    tree.setMimeType(0, mimeType)
    #tree.setAuthorTS()
    tree.setHash(nodeNum)
    return tree
    
def headReq(url):
    req = urllib2.Request(url)
    req.get_method = lambda : 'HEAD'
    
    rsp = urllib2.urlopen(req)
    return rsp

def handleError(e):
    #print e.code()
    print e.read()
    #errorNotification(e)
    
""" fetchWeb(url:string, imgs:boolean=None, comicID:int=None)
fetches requested URL from web, parses it and returns it in a PageTree object.
imgs is a boolean that specifies whether to retrieve the whole image or just headers
"""
def fetchWeb(url, filt, comicID=None, imgs=None):

    try:
        tree   = LunarModule.pageTree.PageTree(None)
        nodeID = 0                                
        
        rsp  = urllib2.urlopen(url)                      # GET request to fill root
        soup = BeautifulSoup(rsp.read())

        pageStr    = soup.prettify()
        headerDict = rsp.info()
        url = rsp.geturl()
       
        tree = fillNode(tree, pageStr, headerDict, url, comicID, nodeID, None)       # Fill root node

        tree.loadLinks(pageStr, filt)

        """for b in soup.findAll('img',href=True):            #Process Imgs
            nodeID += 1
            rsp = headReq(b)
            fillNode(tree, pageStr, headerDict, url, comicID, nodeID, 0)"""

        return tree

    except urllib2.HTTPError as e:
        handleError(e)
    
if __name__ == "__main__":
    testTree = fetchWeb("http://www.amazon.com/", 0)
    pass
